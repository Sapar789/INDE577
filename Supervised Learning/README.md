

# **Supervised Learning**

A key component of machine learning is supervised learning, in which models are trained on input-output pairs with the aim of discovering a mapping from features to labels using historical data.  Supervised algorithms can make very accurate predictions for fresh, unknown data when given access to labeled training examples.

 Numerous real-world applications, including weather forecasting, event classification, financial forecasting, and health diagnostics, make extensive use of these models.  Regression, which predicts continuous values, and classification, which predicts categories, are the two primary categories of supervised tasks.

 This folder contains a number of supervised learning models that were trained on a Texas weather dataset to either identify weather conditions or forecast temperature-related parameters.



## **Topics Covered**

This section includes individual projects that apply core supervised learning algorithms, each implemented and tested on the same Texas weather dataset:

### **1. K-Nearest Neighbors (KNN)**
- In this project, K-Nearest Neighbors algorithm is used to identify 'extremely hot' days versus 'normal' days.

### **2. Decision Trees**
- In this project, Decision Tree algorithm is used to classify weather conditions in Texas, specifically focusing on identifying 'extremely hot' days versus 'normal' days.

### **Gradient Descent**
- In this project, Gradient Descent model is used to predict Solar Radiation

### **4. Logistic Regression**
- Three aspects of Logistic Regression is explored in this project. They are **Binary Logistic Regression**, **Multinomial logistic regression** and **Probability estimation**.

### **5. Perceptron**
- In this project, both single and multi layer perceptron were explored.


### 6. Ensemble Learning & Random Forest**
- In this project, popular ensemble techniques like **Bagging**, **Boosting**, and **Stacking** were explored.

### **8. Linear Regression**
- This project explored **Simple** and **Multi** linear regressions on the same dataset.


## **Files in This Folder**

Each notebook explores one algorithm in depth:

- `The_K_Nearest_Neighbors.ipynb`  
- `Decision_Trees.ipynb`  
- `Neural_Nets_I_and_Gradient_Descent.ipynb`  
- `Logistic_Regression.ipynb`  
- `Perceptron.ipynb`  
- `Multilayer_Perceptron.ipynb`  
- `Ensemble_Learning_and_Random_Forest.ipynb`  
- `Linear_Regression.ipynb`  
- `README.md` (this file)








