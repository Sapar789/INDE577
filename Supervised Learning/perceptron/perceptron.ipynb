{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed8a3b6",
   "metadata": {},
   "source": [
    "# Perceptron for Texas Weather Classification\n",
    "\n",
    "This notebook implements the Perceptron algorithm to classify weather conditions in Texas, specifically focusing on identifying extreme weather events. We'll explore both single-layer and multi-layer perceptron approaches.\n",
    "\n",
    "## Overview\n",
    "The Perceptron is one of the simplest forms of artificial neural networks. In this notebook, we'll:\n",
    "1. Implement a single-layer perceptron for binary classification\n",
    "2. Create a multi-layer perceptron (MLP) for more complex pattern recognition\n",
    "3. Compare their performances on weather classification\n",
    "4. Analyze the impact of different architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38d70c",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "We'll use the following libraries:\n",
    "- `numpy` and `pandas` for data manipulation\n",
    "- `matplotlib` and `seaborn` for visualization\n",
    "- `sklearn` for machine learning implementations\n",
    "- `MLPClassifier` for multi-layer perceptron\n",
    "- `Perceptron` for single-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec73b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_networks import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6212a85",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "We'll work with weather data from Texas, focusing on the following features:\n",
    "- Maximum temperature\n",
    "- Minimum temperature\n",
    "- Humidity\n",
    "- Wind speed\n",
    "- Precipitation\n",
    "- Pressure\n",
    "\n",
    "Our target variable will be a binary classification indicating whether a day is considered extreme (high temperature or heavy precipitation) or normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a42eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather data\n",
    "df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Define features for classification\n",
    "features = [\n",
    "    'max_temp',\n",
    "    'min_temp',\n",
    "    'humidity',\n",
    "    'wind_speed',\n",
    "    'precipitation',\n",
    "    'pressure'\n",
    "]\n",
    "\n",
    "# Create target variable (1 for extreme weather days, 0 for normal days)\n",
    "df['is_extreme'] = ((df['max_temp'] >= 95) | (df['precipitation'] >= 2.0)).astype(int)\n",
    "\n",
    "# Split features and target\n",
    "X = df[features].values\n",
    "y = df['is_extreme'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20284ac8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Let's visualize our data to understand:\n",
    "1. Feature correlations through a heatmap\n",
    "2. Distribution of extreme vs normal days\n",
    "3. Relationship between key features (temperature and humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a63db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[features + ['is_extreme']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution of target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='is_extreme')\n",
    "plt.title('Distribution of Extreme vs Normal Days')\n",
    "plt.xlabel('Is Extreme Day')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plots for feature pairs\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df, x='max_temp', y='humidity', hue='is_extreme', alpha=0.6)\n",
    "plt.title('Temperature vs Humidity (Colored by Extreme Weather)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233f076",
   "metadata": {},
   "source": [
    "## Single-Layer Perceptron\n",
    "The single-layer perceptron is the simplest form of neural network. It:\n",
    "1. Takes input features\n",
    "2. Applies weights and bias\n",
    "3. Uses an activation function (step function) to make binary predictions\n",
    "\n",
    "We'll implement this to establish a baseline for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train single-layer perceptron\n",
    "perceptron = Perceptron(random_state=42, max_iter=1000)\n",
    "perceptron.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = perceptron.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Single-layer Perceptron)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Plot decision boundary for two features\n",
    "def plot_decision_boundary(X, y, model, feature1, feature2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X[y == 0][:, feature1], X[y == 0][:, feature2], \n",
    "                c='blue', label='Normal')\n",
    "    plt.scatter(X[y == 1][:, feature1], X[y == 1][:, feature2], \n",
    "                c='red', label='Extreme')\n",
    "    \n",
    "    # Create a grid of points\n",
    "    x_min, x_max = X[:, feature1].min() - 1, X[:, feature1].max() + 1\n",
    "    y_min, y_max = X[:, feature2].min() - 1, X[:, feature2].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    \n",
    "    # Make predictions on the grid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.xlabel(features[feature1])\n",
    "    plt.ylabel(features[feature2])\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision boundary for temperature and humidity\n",
    "plot_decision_boundary(X_train_scaled, y_train, perceptron, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14960b54",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)\n",
    "The multi-layer perceptron is a more sophisticated neural network that:\n",
    "1. Contains multiple layers of neurons\n",
    "2. Uses non-linear activation functions\n",
    "3. Can learn more complex patterns through backpropagation\n",
    "\n",
    "We'll implement an MLP with two hidden layers to potentially improve our classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2463e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multi-layer perceptron\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Multi-layer Perceptron)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aeb706",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Let's compare the performance of both models using:\n",
    "1. Cross-validation scores for robust evaluation\n",
    "2. ROC curves to visualize classification performance\n",
    "3. Confusion matrices to understand prediction patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performances\n",
    "models = {\n",
    "    'Single-layer Perceptron': perceptron,\n",
    "    'Multi-layer Perceptron': mlp\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f'\\n{name} Cross-validation scores:', scores)\n",
    "    print(f'{name} Average CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')\n",
    "\n",
    "# Plot ROC curves for both models\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Single-layer Perceptron ROC curve\n",
    "y_pred_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Multi-layer Perceptron - AUC = {roc_auc:.2f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c668aa",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "Understanding which features contribute most to the model's predictions is crucial. We'll:\n",
    "1. Use permutation importance to measure feature impact\n",
    "2. Visualize feature importance scores\n",
    "3. Analyze which weather conditions are most indicative of extreme events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance using permutation importance\n",
    "result = permutation_importance(mlp, X_test_scaled, y_test, n_repeats=10,\n",
    "                              random_state=42, n_jobs=4)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': result.importances_mean,\n",
    "    'std': result.importances_std\n",
    "})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "plt.title('Feature Importance (Multi-layer Perceptron)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance values\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649cc5a",
   "metadata": {},
   "source": [
    "## Neural Network Architecture Analysis\n",
    "The performance of neural networks heavily depends on their architecture. We'll:\n",
    "1. Test different network configurations\n",
    "2. Compare their performance metrics\n",
    "3. Identify the optimal architecture for our weather classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different neural network architectures\n",
    "architectures = [\n",
    "    (50,),           # Single hidden layer with 50 neurons\n",
    "    (100,),          # Single hidden layer with 100 neurons\n",
    "    (50, 25),        # Two hidden layers with 50 and 25 neurons\n",
    "    (100, 50),       # Two hidden layers with 100 and 50 neurons\n",
    "    (100, 50, 25)    # Three hidden layers\n",
    "]\n",
    "\n",
    "results = []\n",
    "for arch in architectures:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=arch, max_iter=1000, random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    y_pred = mlp.predict(X_test_scaled)\n",
    "    score = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results.append({\n",
    "        'architecture': str(arch),\n",
    "        'accuracy': score['accuracy'],\n",
    "        'f1-score': score['1']['f1-score']\n",
    "    })\n",
    "\n",
    "# Plot architecture comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_df.plot(x='architecture', y=['accuracy', 'f1-score'], kind='bar')\n",
    "plt.title('Model Performance Across Different Architectures')\n",
    "plt.xlabel('Architecture')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5fb03",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we've:\n",
    "1. Implemented both single-layer and multi-layer perceptrons for weather classification\n",
    "2. Analyzed the performance of different neural network architectures\n",
    "3. Identified the most important features for predicting extreme weather\n",
    "4. Compared the effectiveness of different approaches\n",
    "\n",
    "The results show how neural networks can be used to classify weather conditions, with the multi-layer perceptron generally providing better performance for complex patterns in the data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
